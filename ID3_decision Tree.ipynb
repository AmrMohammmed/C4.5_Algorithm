{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdad29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "492515b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook  Temp Humidity    Wind Play\n",
       "0     Sunny   Hot     High    Weak   No\n",
       "1     Sunny   Hot     High  Strong   No\n",
       "2  Overcast   Hot     High    Weak  Yes\n",
       "3      Rain  Mild     High    Weak  Yes\n",
       "4      Rain  Cool   Normal    Weak  Yes"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_m=pd.read_csv(\"Categorical_Tennis.csv\")\n",
    "train_data_m.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7796b35c",
   "metadata": {},
   "source": [
    "#### Calculating the entropy of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b24fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_total_entropy(train_data, label, class_list):\n",
    "    #class list -> class label (\"play tennis \")\n",
    "    total_row = train_data.shape[0] #the total size of the dataset\n",
    "    total_entr = 0\n",
    "    \n",
    "    for c in class_list: #for each class in the label (\"yes\",\"no\")\n",
    "        total_class_count = train_data[train_data[label] == c].shape[0]\n",
    "        #number of the class\n",
    "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\n",
    "        total_entr += total_class_entr #adding the class entropy to the total entropy of the dataset\n",
    "    return total_entr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33eda3",
   "metadata": {},
   "source": [
    "#### Calculating the entropy for the filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2716a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    class_count = feature_value_data.shape[0]\n",
    "    entropy = 0\n",
    "    \n",
    "    \n",
    "    for c in class_list:\n",
    "        \n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0] #row count of class c \n",
    "        entropy_class = 0\n",
    "        if label_class_count != 0:\n",
    "            probability_class = label_class_count/class_count #probability of the class\n",
    "            entropy_class = - probability_class * np.log2(probability_class)  #entropy\n",
    "        entropy += entropy_class\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae0ad0",
   "metadata": {},
   "source": [
    "#### Calculating information gain for a feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805fdcb",
   "metadata": {},
   "source": [
    "###### After calculating entropy, we have to calculate the information gain of that feature. In math, first, we have to calculate the information of that feature like this: (for the feature Outlook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56827247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_info_gain(feature_name, train_data, label, class_list):\n",
    "    feature_value_list = train_data[feature_name].unique() #unqiue values of the feature\n",
    "    #feature_value_list contain each unique values in each feature \n",
    "    #feature name (outlook, temperature ,....,...etc)\n",
    "\n",
    "    #label =\"play tennis\"\n",
    "    total_row = train_data.shape[0]\n",
    "    #train data = total data set\n",
    "    feature_info = 0.0\n",
    "    \n",
    "    for feature_value in feature_value_list:\n",
    "        #feature_value_list contain each unique values in each feature \n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #filtering rows with that feature_value\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list) #calculcating entropy for the feature value\n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        feature_info += feature_value_probability * feature_value_entropy #calculating information of the feature value\n",
    "        \n",
    "    infoGain= calc_total_entropy(train_data, label, class_list) - feature_info\n",
    "    #print(infoGain)\n",
    "    return  infoGain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c7905",
   "metadata": {},
   "source": [
    "#### Finding the most informative feature (feature with highest information gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a862aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_informative_feature(train_data, label, class_list):\n",
    "    feature_list = train_data.columns.drop(label) #finding the feature names in the dataset\n",
    "                                            #N.B. label is not a feature, so dropping it\n",
    "    max_info_gain = -1\n",
    "    max_info_feature = None\n",
    "    \n",
    "    for feature in feature_list:  #for each feature in the dataset\n",
    "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
    "        if max_info_gain < feature_info_gain: #selecting feature name with highest information gain\n",
    "            max_info_gain = feature_info_gain\n",
    "            max_info_feature = feature\n",
    "            \n",
    "    return max_info_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166bae2",
   "metadata": {},
   "source": [
    "#### Adding a node to the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f61c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
    "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False) #dictionary of the count of unqiue feature value\n",
    "    tree = {} #sub tree or node\n",
    "    \n",
    "    for feature_value, count in feature_value_count_dict.iteritems():\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #dataset with only feature_name = feature_value\n",
    "        \n",
    "        assigned_to_node = False #flag for tracking feature_value is pure class or not\n",
    "        for c in class_list: #for each class\n",
    "            class_count = feature_value_data[feature_value_data[label] == c].shape[0] #count of class c\n",
    "\n",
    "            if class_count == count: #count of (feature_value = count) of class (pure class)\n",
    "                tree[feature_value] = c #adding node to the tree\n",
    "                train_data = train_data[train_data[feature_name] != feature_value] #removing rows with feature_value\n",
    "                assigned_to_node = True\n",
    "        if not assigned_to_node: #not pure class\n",
    "            tree[feature_value] = \"?\" #as feature_value is not a pure class, it should be expanded further, \n",
    "                                      #so the branch is marking with ?\n",
    "            \n",
    "    return tree, train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6514bd8",
   "metadata": {},
   "source": [
    "####  Performing ID3 Algorithm and generating Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92841ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
    "    if train_data.shape[0] != 0: #if dataset becomes enpty after updating\n",
    "        max_info_feature = find_most_informative_feature(train_data, label, class_list) #most informative feature\n",
    "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list) #getting tree node and updated dataset\n",
    "        next_root = None\n",
    "        \n",
    "        if prev_feature_value != None: #add to intermediate node of the tree\n",
    "            root[prev_feature_value] = dict()\n",
    "            root[prev_feature_value][max_info_feature] = tree\n",
    "            next_root = root[prev_feature_value][max_info_feature]\n",
    "        else: #add to root of the tree\n",
    "            root[max_info_feature] = tree\n",
    "            next_root = root[max_info_feature]\n",
    "        \n",
    "        for node, branch in list(next_root.items()): #iterating the tree node\n",
    "            if branch == \"?\": #if it is expandable\n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node] #using the updated dataset\n",
    "                make_tree(next_root, node, feature_value_data, label, class_list) #recursive call with updated dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c48b54",
   "metadata": {},
   "source": [
    "#### Finding unique classes of the label and Starting the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94871bbe",
   "metadata": {},
   "source": [
    "Method description:\n",
    "Generates id3 tree.\n",
    "train_data_m: a pandas dataframe\n",
    "label: string, name of the label of the dataframe (=Play Tennis)\n",
    "returns: (nested) dictionary, the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dee9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(train_data_m, label):\n",
    "    train_data = train_data_m.copy() #getting a copy of the dataset\n",
    "    tree = {} #tree which will be updated\n",
    "    class_list = train_data[label].unique() #getting unqiue classes of the label\n",
    "    make_tree(tree, None, train_data, label, class_list) #start calling recursion\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366bf76",
   "metadata": {},
   "source": [
    "###### Predicting from the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb58a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, instance):\n",
    "    if not isinstance(tree, dict): #if it is leaf node\n",
    "        return tree #return the value\n",
    "    else:\n",
    "        root_node = next(iter(tree)) #getting first key/feature name of the dictionary\n",
    "        feature_value = instance[root_node] #value of the feature\n",
    "        if feature_value in tree[root_node]: #checking the feature value in current tree node\n",
    "            return predict(tree[root_node][feature_value], instance) #goto next feature\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0fa74",
   "metadata": {},
   "source": [
    "##### Evaluating test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e305b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tree, test_data_m, label):\n",
    "    correct_preditct = 0\n",
    "    wrong_preditct = 0\n",
    "    for index, row in test_data_m.iterrows(): #for each row in the dataset\n",
    "        result = predict(tree, test_data_m.iloc[index]) #predict the row\n",
    "        if result == test_data_m[label].iloc[index]: #predicted value and expected value is same or not\n",
    "            correct_preditct += 1 #increase correct count\n",
    "        else:\n",
    "            wrong_preditct += 1 #increase incorrect count\n",
    "    accuracy = correct_preditct / (correct_preditct + wrong_preditct) #calculating accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3f09f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_m = pd.read_csv(\"Test_Tennis.csv\") \n",
    "tree = id3(train_data_m ,'Play')\n",
    "#accuracy = evaluate(tree, test_data_m, 'Play') #evaluating the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a80c2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Outlook': {'Sunny': {'Humidity': {'High': 'No', 'Normal': 'Yes'}}, 'Overcast': 'Yes', 'Rain': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}}}\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "924a37df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f764deb",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
